{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Source: \n",
        "\n",
        "*   https://pypi.org/project/gpt-2-simple/#description\n",
        "*   https://medium.com/@stasinopoulos.dimitrios/a-beginners-guide-to-training-and-generating-text-using-gpt2-c2f2e1fbd10a\n",
        "*   https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce#scrollTo=VHdTL8NDbAh3\n",
        "*  https://github.com/ak9250/gpt-2-colab\n",
        "*  https://www.aiweirdness.com/d-and-d-character-bios-now-making-19-03-15/\n",
        "*  https://minimaxir.com/2019/09/howto-gpt2/\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rgNM-NcAZ9aT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zawemi/GS2DIT/blob/main/Class%203/gpt_2_shakespeare.ipynb#scrollTo=4tIUvFbLMUuE)"
      ],
      "metadata": {
        "id": "4tIUvFbLMUuE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Let's teach AI writing like a Shakespeare ðŸŽ“"
      ],
      "metadata": {
        "id": "MofLJqBHAWXI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Installing the model"
      ],
      "metadata": {
        "id": "W7wiPFGQQn9o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQACJ8lyUIR0",
        "outputId": "b0005cfa-1d33-42e4-c7c9-7f21a8547602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gpt-2-simple in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: tensorflow>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2.12.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (1.22.4)\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.10/dist-packages (from gpt-2-simple) (1.10)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.4.8)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.32.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt-2-simple) (3.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.5.1->gpt-2-simple) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.5.1->gpt-2-simple) (0.1.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.5.1->gpt-2-simple) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.5.1->gpt-2-simple) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "#install the library we'll use today\n",
        "!pip install gpt-2-simple"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generating text with basic model"
      ],
      "metadata": {
        "id": "ADzeFwzaQ8cT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing and loading necessary components"
      ],
      "metadata": {
        "id": "d6Ah3D1CRK6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import what we need\n",
        "import gpt_2_simple as gpt2 #for gpt-2 (our AI model)\n",
        "import os #lets us doing things with files and folders\n",
        "import requests #this one helps to dowload from the internet"
      ],
      "metadata": {
        "id": "mLg4pTPDaJJV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#and let's download our AI model\n",
        "gpt2.download_gpt2()   # model is saved into current directory under /models/124M/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIXHjaxvaWsV",
        "outputId": "5a772a1f-6048-47e5-f0ec-0ec28d01bc12"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 333Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 5.02Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 640Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:07, 68.1Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 508Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 7.65Mit/s]\n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 5.83Mit/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#strating the session so we can play with the gpt-2 model\n",
        "sess = gpt2.start_tf_sess()"
      ],
      "metadata": {
        "id": "6CCkn75KbBpg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we load the model from file to use it\n",
        "gpt2.load_gpt2(sess, run_name='124M', checkpoint_dir='models')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsBvHQsxZsyP",
        "outputId": "9e9dbba2-7260-403d-c3e9-a669a9bcb049"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Text generation"
      ],
      "metadata": {
        "id": "mDSFDj78RQJg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#this is how we would start model statement\n",
        "prefix = \"Is there a second Earth?\""
      ],
      "metadata": {
        "id": "-P5_fxZOgGlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the model is generating text\n",
        "gpt2.generate(sess, run_name='124M', checkpoint_dir='models', prefix=prefix, length=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSYqTat0gNDo",
        "outputId": "41978740-7547-4658-c0df-6a03468eea0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is there a second Earth?\n",
            "\n",
            "I don't know. I don't think I can understand that. I mean, I'm not saying it's a planet, but it's a planet with a planet. At the end of the day, we don't know what happened\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generating text with improved (finetuned) model"
      ],
      "metadata": {
        "id": "ML5helfmRjT0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORTANT**\n",
        "</br>Restart the runtime (Runtime -> Restart runtime)"
      ],
      "metadata": {
        "id": "8cEaZKtRPx0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Importing and loading necessary components"
      ],
      "metadata": {
        "id": "NIPDKskeR7i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import what we need\n",
        "import gpt_2_simple as gpt2 #for gpt-2 (our AI model)\n",
        "import os #lets us doing things with files and folders\n",
        "import requests #this one helps to dowload from the internet"
      ],
      "metadata": {
        "id": "eHys5-bWPnhJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get nietzsche texts\n",
        "!wget \"https://s3.amazonaws.com/text-datasets/nietzsche.txt\""
      ],
      "metadata": {
        "id": "dRTQyR7IqaOl",
        "outputId": "149921ad-91bc-4f9d-c246-54f8f490c67f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-24 12:12:48--  https://s3.amazonaws.com/text-datasets/nietzsche.txt\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.225.16, 54.231.138.104, 54.231.164.152, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.225.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 600901 (587K) [text/plain]\n",
            "Saving to: â€˜nietzsche.txt.2â€™\n",
            "\n",
            "nietzsche.txt.2     100%[===================>] 586.82K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-05-24 12:12:48 (4.00 MB/s) - â€˜nietzsche.txt.2â€™ saved [600901/600901]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#game of thrones from https://www.kaggle.com/datasets/khulasasndh/game-of-thrones-books?select=001ssb.txt\n",
        "!gdown \"1CrL1wde_NGO68i5Prd_UNA_oW0cGQsxg&confirm=t\"\n",
        "!mv /content/001ssb.txt /content/got1.txt"
      ],
      "metadata": {
        "id": "pzDNTjJzuKDW",
        "outputId": "ad72f9e0-6d67-47d6-cfff-8de93f5b41ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CrL1wde_NGO68i5Prd_UNA_oW0cGQsxg&confirm=t\n",
            "To: /content/001ssb.txt\n",
            "\r  0% 0.00/1.63M [00:00<?, ?B/s]\r100% 1.63M/1.63M [00:00<00:00, 106MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#let's dowload a file with all Shakespeare plays\n",
        "!wget \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "!mv /content/input.txt /content/shakespeare.txt"
      ],
      "metadata": {
        "id": "9pwWGn5eqBJn",
        "outputId": "b59755af-4d8a-4592-c71a-bee603432b35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-21 15:19:13--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: â€˜input.txtâ€™\n",
            "\n",
            "\rinput.txt             0%[                    ]       0  --.-KB/s               \rinput.txt           100%[===================>]   1.06M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-03-21 15:19:13 (19.9 MB/s) - â€˜input.txtâ€™ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#strating the session so we can play with the gpt-2 model\n",
        "sess = gpt2.start_tf_sess()"
      ],
      "metadata": {
        "id": "A0T2s8RxPnVr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Teaching our model"
      ],
      "metadata": {
        "id": "bvllQvFxR9z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#finetuning with shakespeare.txt (which, to be honest, means that we are teaching the model how to write like a shakespeare)\n",
        "#it takes a lot of time (~15min)...\n",
        "gpt2.finetune(sess, 'got1.txt', steps=500)   # steps is max number of training steps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RJetxF6UOfY",
        "outputId": "a1a36392-b720-45e8-c785-827186bbf144"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.67s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 433157 tokens\n",
            "Training...\n",
            "[1 | 7.12] loss=3.41 avg=3.41\n",
            "[2 | 9.25] loss=3.42 avg=3.42\n",
            "[3 | 11.39] loss=3.34 avg=3.39\n",
            "[4 | 13.54] loss=3.20 avg=3.34\n",
            "[5 | 15.71] loss=3.27 avg=3.33\n",
            "[6 | 17.90] loss=3.27 avg=3.32\n",
            "[7 | 20.05] loss=3.28 avg=3.31\n",
            "[8 | 22.23] loss=3.14 avg=3.29\n",
            "[9 | 24.39] loss=3.15 avg=3.27\n",
            "[10 | 26.54] loss=3.16 avg=3.26\n",
            "[11 | 28.71] loss=3.28 avg=3.26\n",
            "[12 | 30.89] loss=3.17 avg=3.26\n",
            "[13 | 33.08] loss=3.24 avg=3.25\n",
            "[14 | 35.27] loss=3.29 avg=3.26\n",
            "[15 | 37.44] loss=3.27 avg=3.26\n",
            "[16 | 39.62] loss=3.11 avg=3.25\n",
            "[17 | 41.82] loss=3.07 avg=3.24\n",
            "[18 | 44.01] loss=3.04 avg=3.22\n",
            "[19 | 46.20] loss=3.09 avg=3.22\n",
            "[20 | 48.40] loss=3.12 avg=3.21\n",
            "[21 | 50.60] loss=3.07 avg=3.20\n",
            "[22 | 52.81] loss=3.15 avg=3.20\n",
            "[23 | 55.03] loss=3.00 avg=3.19\n",
            "[24 | 57.25] loss=3.05 avg=3.19\n",
            "[25 | 59.48] loss=3.16 avg=3.18\n",
            "[26 | 61.70] loss=3.15 avg=3.18\n",
            "[27 | 63.93] loss=3.18 avg=3.18\n",
            "[28 | 66.17] loss=2.93 avg=3.17\n",
            "[29 | 68.42] loss=3.07 avg=3.17\n",
            "[30 | 70.67] loss=3.07 avg=3.16\n",
            "[31 | 72.92] loss=2.99 avg=3.16\n",
            "[32 | 75.17] loss=2.99 avg=3.15\n",
            "[33 | 77.43] loss=3.14 avg=3.15\n",
            "[34 | 79.70] loss=3.06 avg=3.15\n",
            "[35 | 81.96] loss=3.23 avg=3.15\n",
            "[36 | 84.21] loss=3.15 avg=3.15\n",
            "[37 | 86.46] loss=3.08 avg=3.15\n",
            "[38 | 88.71] loss=2.96 avg=3.14\n",
            "[39 | 90.96] loss=3.06 avg=3.14\n",
            "[40 | 93.20] loss=2.93 avg=3.13\n",
            "[41 | 95.44] loss=3.05 avg=3.13\n",
            "[42 | 97.67] loss=3.08 avg=3.13\n",
            "[43 | 99.91] loss=3.02 avg=3.13\n",
            "[44 | 102.14] loss=3.13 avg=3.13\n",
            "[45 | 104.36] loss=2.99 avg=3.12\n",
            "[46 | 106.59] loss=3.06 avg=3.12\n",
            "[47 | 108.81] loss=2.79 avg=3.11\n",
            "[48 | 111.03] loss=3.01 avg=3.11\n",
            "[49 | 113.25] loss=3.02 avg=3.11\n",
            "[50 | 115.47] loss=2.98 avg=3.10\n",
            "[51 | 117.69] loss=2.96 avg=3.10\n",
            "[52 | 119.90] loss=2.96 avg=3.10\n",
            "[53 | 122.12] loss=3.00 avg=3.10\n",
            "[54 | 124.33] loss=3.10 avg=3.10\n",
            "[55 | 126.56] loss=3.00 avg=3.09\n",
            "[56 | 128.77] loss=2.96 avg=3.09\n",
            "[57 | 130.99] loss=3.10 avg=3.09\n",
            "[58 | 133.21] loss=2.99 avg=3.09\n",
            "[59 | 135.43] loss=2.93 avg=3.08\n",
            "[60 | 137.65] loss=2.96 avg=3.08\n",
            "[61 | 139.88] loss=2.94 avg=3.08\n",
            "[62 | 142.11] loss=2.90 avg=3.07\n",
            "[63 | 144.33] loss=2.87 avg=3.07\n",
            "[64 | 146.56] loss=2.94 avg=3.07\n",
            "[65 | 148.79] loss=3.00 avg=3.07\n",
            "[66 | 151.03] loss=2.94 avg=3.06\n",
            "[67 | 153.27] loss=2.85 avg=3.06\n",
            "[68 | 155.50] loss=2.94 avg=3.06\n",
            "[69 | 157.74] loss=2.88 avg=3.05\n",
            "[70 | 159.99] loss=2.85 avg=3.05\n",
            "[71 | 162.22] loss=2.96 avg=3.05\n",
            "[72 | 164.46] loss=2.83 avg=3.04\n",
            "[73 | 166.70] loss=2.98 avg=3.04\n",
            "[74 | 168.93] loss=2.98 avg=3.04\n",
            "[75 | 171.16] loss=2.93 avg=3.04\n",
            "[76 | 173.39] loss=2.86 avg=3.04\n",
            "[77 | 175.63] loss=2.88 avg=3.03\n",
            "[78 | 177.86] loss=2.93 avg=3.03\n",
            "[79 | 180.10] loss=2.95 avg=3.03\n",
            "[80 | 182.32] loss=2.86 avg=3.03\n",
            "[81 | 184.55] loss=2.84 avg=3.02\n",
            "[82 | 186.78] loss=2.88 avg=3.02\n",
            "[83 | 189.02] loss=2.79 avg=3.02\n",
            "[84 | 191.24] loss=2.93 avg=3.01\n",
            "[85 | 193.48] loss=2.96 avg=3.01\n",
            "[86 | 195.70] loss=2.77 avg=3.01\n",
            "[87 | 197.93] loss=2.83 avg=3.01\n",
            "[88 | 200.17] loss=2.79 avg=3.00\n",
            "[89 | 202.40] loss=2.92 avg=3.00\n",
            "[90 | 204.62] loss=2.96 avg=3.00\n",
            "[91 | 206.85] loss=2.85 avg=3.00\n",
            "[92 | 209.08] loss=2.86 avg=3.00\n",
            "[93 | 211.30] loss=2.89 avg=2.99\n",
            "[94 | 213.54] loss=2.91 avg=2.99\n",
            "[95 | 215.76] loss=2.80 avg=2.99\n",
            "[96 | 217.99] loss=2.78 avg=2.99\n",
            "[97 | 220.22] loss=2.83 avg=2.98\n",
            "[98 | 222.44] loss=2.92 avg=2.98\n",
            "[99 | 224.67] loss=2.77 avg=2.98\n",
            "[100 | 226.90] loss=2.84 avg=2.98\n",
            "======== SAMPLE 1 ========\n",
            " to see a hundred people, who went out to kill him, to die with him.\" \n",
            "The raven had no hair, his ears thin and grey, his face twisted with rage. He looked down upon \n",
            "Ethan as though he were a child. \"I will not kill a human,\" he said in his fury. \"I cannot.\" \n",
            "\"You were not only killing him.\" \n",
            "\"You were also butchering our sons.\" \n",
            "\"We were butchering your sons.\" \n",
            "Eddard Stark was angry with Lysa. \"How dare you try to murder a child, boy?\" \n",
            "\"You are the same child you killed,\" the raven replied. \"A child born of Winter.\" \n",
            "The Hound was biting. He was breathing heavily now. It was now dawn. The rain had stopped and the snow had \n",
            "closed over the ridge, so dark that a shadow was cast in the cold air. \n",
            "\"You will not kill a boy,\" the raven said. \"You will only kill your father.\" \n",
            "\"Do what you will,\" the captain's son said, giving an angry look that made no sense. He stood up. \n",
            "The raven flew at him. \"Please. This is not good.\" \n",
            "Eddard Stark looked back down upon the Hound. \"I will not harm a man in your care, or your son.\" He \n",
            "pulled his \n",
            "klingon's face close and held them both close. \"No, Lord Karstark not, it is true, but it will not make that son \n",
            "less a child than before. You must protect him. Do what you will. I cannot live by my own weakness. I shall defend you, \n",
            "you. You, your child. You are my lord. And with you, I beg you. Lord Karstark shall be my brother in death.\" \n",
            "His brother, Bran's brother. If the Hound was the Lord of Winter or even the Lord of Men, he was Lord Black. If not, then he was \n",
            "Lord Black if not. There were some who would sooner kill him than die by his own hand. He had killed his own son. \n",
            "They laughed, and a second time Bran had a frightened look on his face, and then he heard them. The captain's son \n",
            "sent the Hound back to the yard. He stood there, face still, staring at the snow, breathing heavily, for some time, then \n",
            "he turned. \n",
            "\"I will not have it done, my lord,\" the captain's son said; he was the Hound now, with the klepton of blood, his \n",
            "hair still wet with blood, his eyes still black. \"Do what you will.\" \n",
            "Eddard Stark was now half-sentenceless, his face still black. The Hound had no hair, and his eyes were dark red \n",
            "now while his teeth still felt razor sharp. \"Now,\" he said, \"for what I will.\" He turned and looked back at him. \n",
            "The captain's son did not answer . . . but as he turned the knight's face to him, the ravens flew at him. \n",
            "Eddard Stark was in the stable now. He turned back to the door. \"I will not take the khal's khas,\" he \n",
            "called out. \"Lord Karstark cannot be taken!\" He bowed. \n",
            "Page 196\n",
            "\n",
            "\"A dragon must be saved,\" said the captain's son. \"You must protect yourself.\" \n",
            "The Hound shook his head. \"I shall not take Khal Drogo's khas, son.\" \n",
            "They stood there silent. The captains of the Kingsguard were gone. \"I'll call you,\" they said, together. \"A Lord of the \n",
            "Storms by now.\" They looked at the others and looked, and saw. \"This is the end of the story, my boy.\" \n",
            "He rose, brushed his teeth together, and bowed respectfully. \"We are in need of warriors.\" \n",
            "\"A thousand warriors!\" yelled the others. \"That is as good as you have been.\" They all took their leave and \n",
            "passed through the room, where the Hound was sitting. He put one hand on his thick chest to shield his face. \"I will honor you, \n",
            "your son.\" \n",
            "The last few words were a cry for help, a call for help, and as for no help. \"The Khal Drogo's \n",
            "crippled horse cannot be ridden safely,\" murmured the two women behind him. \"Khal Drogo must be \n",
            "carried now. Your mother was a stubborn enemy, and you do not understand her.\" \n",
            "His brothers had been standing beside him since they had fled Lordaeron, with Ser Meryn Trant, with \n",
            "the others around them. \"I pray you to have a seat\n",
            "\n",
            "[101 | 241.71] loss=2.98 avg=2.98\n",
            "[102 | 243.94] loss=2.81 avg=2.97\n",
            "[103 | 246.18] loss=2.84 avg=2.97\n",
            "[104 | 248.41] loss=2.69 avg=2.97\n",
            "[105 | 250.65] loss=2.74 avg=2.96\n",
            "[106 | 252.89] loss=2.83 avg=2.96\n",
            "[107 | 255.13] loss=2.66 avg=2.96\n",
            "[108 | 257.37] loss=2.80 avg=2.96\n",
            "[109 | 259.61] loss=2.83 avg=2.95\n",
            "[110 | 261.85] loss=2.66 avg=2.95\n",
            "[111 | 264.09] loss=2.82 avg=2.95\n",
            "[112 | 266.33] loss=2.77 avg=2.95\n",
            "[113 | 268.57] loss=2.79 avg=2.94\n",
            "[114 | 270.80] loss=2.80 avg=2.94\n",
            "[115 | 273.03] loss=2.76 avg=2.94\n",
            "[116 | 275.27] loss=2.76 avg=2.94\n",
            "[117 | 277.50] loss=2.76 avg=2.93\n",
            "[118 | 279.73] loss=2.86 avg=2.93\n",
            "[119 | 281.96] loss=2.67 avg=2.93\n",
            "[120 | 284.20] loss=2.68 avg=2.92\n",
            "[121 | 286.43] loss=2.69 avg=2.92\n",
            "[122 | 288.66] loss=2.62 avg=2.92\n",
            "[123 | 290.89] loss=2.80 avg=2.92\n",
            "[124 | 293.12] loss=2.73 avg=2.91\n",
            "[125 | 295.35] loss=2.69 avg=2.91\n",
            "[126 | 297.58] loss=2.74 avg=2.91\n",
            "[127 | 299.81] loss=2.67 avg=2.90\n",
            "[128 | 302.04] loss=2.65 avg=2.90\n",
            "[129 | 304.27] loss=2.80 avg=2.90\n",
            "[130 | 306.50] loss=2.67 avg=2.90\n",
            "[131 | 308.73] loss=2.65 avg=2.89\n",
            "[132 | 310.96] loss=2.74 avg=2.89\n",
            "[133 | 313.20] loss=2.53 avg=2.89\n",
            "[134 | 315.43] loss=2.69 avg=2.88\n",
            "[135 | 317.66] loss=2.69 avg=2.88\n",
            "[136 | 319.90] loss=2.80 avg=2.88\n",
            "[137 | 322.13] loss=2.83 avg=2.88\n",
            "[138 | 324.37] loss=2.54 avg=2.87\n",
            "[139 | 326.60] loss=2.92 avg=2.87\n",
            "[140 | 328.83] loss=2.85 avg=2.87\n",
            "[141 | 331.07] loss=2.78 avg=2.87\n",
            "[142 | 333.30] loss=2.69 avg=2.87\n",
            "[143 | 335.53] loss=2.64 avg=2.87\n",
            "[144 | 337.77] loss=2.68 avg=2.87\n",
            "[145 | 340.00] loss=2.71 avg=2.86\n",
            "[146 | 342.24] loss=2.55 avg=2.86\n",
            "[147 | 344.47] loss=2.71 avg=2.86\n",
            "[148 | 346.70] loss=2.79 avg=2.86\n",
            "[149 | 348.94] loss=2.58 avg=2.85\n",
            "[150 | 351.17] loss=2.75 avg=2.85\n",
            "[151 | 353.41] loss=2.84 avg=2.85\n",
            "[152 | 355.64] loss=2.76 avg=2.85\n",
            "[153 | 357.87] loss=2.85 avg=2.85\n",
            "[154 | 360.11] loss=2.58 avg=2.85\n",
            "[155 | 362.36] loss=2.78 avg=2.85\n",
            "[156 | 364.59] loss=2.74 avg=2.84\n",
            "[157 | 366.83] loss=2.56 avg=2.84\n",
            "[158 | 369.06] loss=2.74 avg=2.84\n",
            "[159 | 371.30] loss=2.74 avg=2.84\n",
            "[160 | 373.54] loss=2.72 avg=2.84\n",
            "[161 | 375.78] loss=2.69 avg=2.84\n",
            "[162 | 378.01] loss=2.73 avg=2.83\n",
            "[163 | 380.24] loss=2.53 avg=2.83\n",
            "[164 | 382.47] loss=2.56 avg=2.83\n",
            "[165 | 384.71] loss=2.77 avg=2.83\n",
            "[166 | 386.95] loss=2.80 avg=2.83\n",
            "[167 | 389.19] loss=2.67 avg=2.82\n",
            "[168 | 391.41] loss=2.63 avg=2.82\n",
            "[169 | 393.64] loss=2.62 avg=2.82\n",
            "[170 | 395.88] loss=2.61 avg=2.82\n",
            "[171 | 398.11] loss=2.58 avg=2.81\n",
            "[172 | 400.34] loss=2.67 avg=2.81\n",
            "[173 | 402.58] loss=2.61 avg=2.81\n",
            "[174 | 404.81] loss=2.68 avg=2.81\n",
            "[175 | 407.05] loss=2.79 avg=2.81\n",
            "[176 | 409.29] loss=2.49 avg=2.80\n",
            "[177 | 411.52] loss=2.40 avg=2.80\n",
            "[178 | 413.75] loss=2.70 avg=2.80\n",
            "[179 | 415.98] loss=2.43 avg=2.79\n",
            "[180 | 418.21] loss=2.59 avg=2.79\n",
            "[181 | 420.44] loss=2.48 avg=2.79\n",
            "[182 | 422.68] loss=2.59 avg=2.78\n",
            "[183 | 424.91] loss=2.71 avg=2.78\n",
            "[184 | 427.14] loss=2.43 avg=2.78\n",
            "[185 | 429.37] loss=2.75 avg=2.78\n",
            "[186 | 431.61] loss=2.42 avg=2.78\n",
            "[187 | 433.85] loss=2.66 avg=2.77\n",
            "[188 | 436.09] loss=2.76 avg=2.77\n",
            "[189 | 438.32] loss=2.65 avg=2.77\n",
            "[190 | 440.55] loss=2.66 avg=2.77\n",
            "[191 | 442.78] loss=2.60 avg=2.77\n",
            "[192 | 445.01] loss=2.30 avg=2.76\n",
            "[193 | 447.25] loss=2.56 avg=2.76\n",
            "[194 | 449.48] loss=2.49 avg=2.76\n",
            "[195 | 451.71] loss=2.74 avg=2.76\n",
            "[196 | 453.94] loss=2.37 avg=2.75\n",
            "[197 | 456.17] loss=2.38 avg=2.75\n",
            "[198 | 458.41] loss=2.67 avg=2.75\n",
            "[199 | 460.64] loss=2.70 avg=2.75\n",
            "[200 | 462.87] loss=2.71 avg=2.75\n",
            "======== SAMPLE 1 ========\n",
            " wasn't the last time she'd had her eyes on him.\" \n",
            "\"Well, I wonder, Mariah.\" \n",
            "\"Oh, surely . . . but the thought makes no sense to me.\" \n",
            "\"The boy would love to see her,\" the woman replied. She turned back to look at the \n",
            "river. \"Oh, he loves to see her. I must have her. The man, though, has not come so near.\" \n",
            "\"My lord?\" The river grew heavy. The wind rumbled with the wood. \n",
            "He had only to look back at the girl on the bank to see that he could feel the weight of the rock. \"I \n",
            "cannot bear to go out by myself again.\" \n",
            "Page 117\n",
            "\n",
            "\"Is something wrong?\" \n",
            "\"Something is wrong. That is why you came with me. You might find me . . .\" \n",
            "\"Where is Lord Frey?\" She was almost too frightened to reply. She felt his skin. \n",
            "\"My uncle found me here last night.\" The woman sighed. \"This is Sansa's man. You ought to be \n",
            "trying.\" \n",
            "Sansa did not know where she was getting her answer. She should have taken the girl with her. \n",
            "\"That poor boy . . .\" Prince Joffrey's pale face flushed almost as they talked. \"Your uncle?\" \n",
            "\"The lord Commander of the Night's Watch has not spoken. He is to be summoned to attend me on his return. His \n",
            "sorts of wine are being sold to the Jogos and the Vale of Arryn, so that we may have him \n",
            "to sell and make my bed in Hand's arms. And of course, I am to pay for the rest of it. Sansa, sell me my \n",
            "sweet little sister. I would pay you a fair price if I were to sell you to a \n",
            "lord like Jory.\" \n",
            "Sansa was utterly silent. Jory was so great an old friend, it frightened her. \"If it be true, my honor . . . I \n",
            "wager you are the younger.\" \n",
            "\"Oh, my lord, truly . . . . is it true?\" \n",
            "\"No,\" she whispered. \"I should have expected it.\" \n",
            "\"Your Grace, I have heard from Jory the word that your lady friend of three years, Ser \n",
            "Rodrik,\" she added. \"The Hound is at Hand, he says.\" \n",
            "\"I have a message from Lord Karstark,\" Jory replied. \"It is told to my uncle, in person. I must \n",
            "prompt you.\" Ser Rodrik was still in his tent, wearing a pale cloak of blue painted in gold. \n",
            "\"I thank you for your assistance at Hand, Ser Jyne and your sister Sansa, both of you here . . . but \n",
            "you are more urgent than you realize. I shall need Sansa if I am to bring your horses. If you can spare \n",
            "more time, I shall send you back your letter from the Eastron, along with a letter of complaint to Lysa Arryn.\" \n",
            "\"The man is an eunuch, my lady,\" Ser Rodrik said. He was of a late age. Marillion had not been heard, \n",
            "yet she thought he might have, or rather, that Sansa was at her uncle's door to let them know of her \n",
            "intent after she had passed her brief glimpse of his pale face. \"A letter from the gods ... I \n",
            "am afraid I cannot arrange you for him to meet with you, my lord. Sansa needs the help of you.\" \n",
            "Sansa looked to her sister. Her eyes widened in sudden hope. Her fingers were trembling, and she \n",
            "was afraid she might faint. Finally she sat up straight again. \n",
            "\"I do not want to see the Hound.\" \n",
            "Page 119\n",
            "\n",
            "The hound did not dare go. His face was pale, his whiskers dark. Sansa stared at tears in his father's \n",
            "red hair, her fingers tangled in the folds of his cloak. \"No,\" she whispered, her voice faint. Tears ran \n",
            "from his eyes, and from his cheek where the tear had been filled back to back so thick that his skin \n",
            "was still sticky from the blows she had taken on his belly. \"Jory, help you to the letter. I shall \n",
            "ask some business.\" Ser Rodrik gave her a weary glance. \"The message can only come from outside, and \n",
            "only from inside. You shall not enter your sister's bedchamber, Sansa. You must not even look at the roses in the \n",
            "heart. Tell your uncle to call her.\" \n",
            "Sansa turned away from the door to Sansa's room, but suddenly she was alone. The words did not\n",
            "\n",
            "[201 | 476.71] loss=2.55 avg=2.74\n",
            "[202 | 478.94] loss=2.43 avg=2.74\n",
            "[203 | 481.17] loss=2.36 avg=2.74\n",
            "[204 | 483.42] loss=2.58 avg=2.74\n",
            "[205 | 485.65] loss=2.57 avg=2.73\n",
            "[206 | 487.88] loss=2.63 avg=2.73\n",
            "[207 | 490.11] loss=2.10 avg=2.72\n",
            "[208 | 492.34] loss=2.55 avg=2.72\n",
            "[209 | 494.58] loss=2.59 avg=2.72\n",
            "[210 | 496.81] loss=2.57 avg=2.72\n",
            "[211 | 499.04] loss=2.57 avg=2.72\n",
            "[212 | 501.27] loss=2.63 avg=2.72\n",
            "[213 | 503.51] loss=2.63 avg=2.72\n",
            "[214 | 505.74] loss=2.50 avg=2.71\n",
            "[215 | 507.98] loss=2.45 avg=2.71\n",
            "[216 | 510.21] loss=2.68 avg=2.71\n",
            "[217 | 512.44] loss=2.42 avg=2.71\n",
            "[218 | 514.68] loss=2.40 avg=2.70\n",
            "[219 | 516.91] loss=2.50 avg=2.70\n",
            "[220 | 519.15] loss=2.49 avg=2.70\n",
            "[221 | 521.38] loss=2.58 avg=2.70\n",
            "[222 | 523.62] loss=2.32 avg=2.69\n",
            "[223 | 525.85] loss=2.43 avg=2.69\n",
            "[224 | 528.08] loss=2.39 avg=2.69\n",
            "[225 | 530.32] loss=2.61 avg=2.69\n",
            "[226 | 532.56] loss=2.51 avg=2.68\n",
            "[227 | 534.79] loss=2.55 avg=2.68\n",
            "[228 | 537.04] loss=2.45 avg=2.68\n",
            "[229 | 539.27] loss=2.58 avg=2.68\n",
            "[230 | 541.51] loss=2.40 avg=2.68\n",
            "[231 | 543.75] loss=2.50 avg=2.67\n",
            "[232 | 545.98] loss=2.54 avg=2.67\n",
            "[233 | 548.21] loss=2.29 avg=2.67\n",
            "[234 | 550.45] loss=2.58 avg=2.67\n",
            "[235 | 552.69] loss=2.39 avg=2.66\n",
            "[236 | 554.92] loss=2.25 avg=2.66\n",
            "[237 | 557.16] loss=2.45 avg=2.66\n",
            "[238 | 559.40] loss=2.15 avg=2.65\n",
            "[239 | 561.63] loss=2.39 avg=2.65\n",
            "[240 | 563.87] loss=2.44 avg=2.65\n",
            "[241 | 566.11] loss=2.26 avg=2.64\n",
            "[242 | 568.35] loss=2.31 avg=2.64\n",
            "[243 | 570.59] loss=2.45 avg=2.64\n",
            "[244 | 572.83] loss=2.42 avg=2.63\n",
            "[245 | 575.06] loss=2.44 avg=2.63\n",
            "[246 | 577.29] loss=2.52 avg=2.63\n",
            "[247 | 579.53] loss=2.51 avg=2.63\n",
            "[248 | 581.78] loss=2.49 avg=2.63\n",
            "[249 | 584.01] loss=2.54 avg=2.63\n",
            "[250 | 586.25] loss=2.47 avg=2.63\n",
            "[251 | 588.48] loss=2.46 avg=2.62\n",
            "[252 | 590.71] loss=2.56 avg=2.62\n",
            "[253 | 592.95] loss=2.49 avg=2.62\n",
            "[254 | 595.20] loss=2.48 avg=2.62\n",
            "[255 | 597.43] loss=2.40 avg=2.62\n",
            "[256 | 599.67] loss=2.49 avg=2.62\n",
            "[257 | 601.90] loss=2.36 avg=2.61\n",
            "[258 | 604.14] loss=2.65 avg=2.61\n",
            "[259 | 606.38] loss=2.42 avg=2.61\n",
            "[260 | 608.62] loss=2.36 avg=2.61\n",
            "[261 | 610.86] loss=2.34 avg=2.61\n",
            "[262 | 613.09] loss=2.13 avg=2.60\n",
            "[263 | 615.32] loss=2.54 avg=2.60\n",
            "[264 | 617.56] loss=2.53 avg=2.60\n",
            "[265 | 619.80] loss=2.65 avg=2.60\n",
            "[266 | 622.03] loss=2.45 avg=2.60\n",
            "[267 | 624.26] loss=2.23 avg=2.59\n",
            "[268 | 626.50] loss=2.42 avg=2.59\n",
            "[269 | 628.73] loss=2.48 avg=2.59\n",
            "[270 | 630.97] loss=2.39 avg=2.59\n",
            "[271 | 633.20] loss=2.56 avg=2.59\n",
            "[272 | 635.44] loss=2.32 avg=2.59\n",
            "[273 | 637.67] loss=2.32 avg=2.58\n",
            "[274 | 639.91] loss=2.16 avg=2.58\n",
            "[275 | 642.14] loss=2.22 avg=2.57\n",
            "[276 | 644.38] loss=2.49 avg=2.57\n",
            "[277 | 646.61] loss=2.28 avg=2.57\n",
            "[278 | 648.84] loss=2.41 avg=2.57\n",
            "[279 | 651.07] loss=2.34 avg=2.57\n",
            "[280 | 653.31] loss=2.27 avg=2.56\n",
            "[281 | 655.55] loss=2.16 avg=2.56\n",
            "[282 | 657.78] loss=2.19 avg=2.56\n",
            "[283 | 660.01] loss=2.52 avg=2.56\n",
            "[284 | 662.24] loss=2.54 avg=2.55\n",
            "[285 | 664.47] loss=2.23 avg=2.55\n",
            "[286 | 666.72] loss=2.25 avg=2.55\n",
            "[287 | 668.95] loss=2.53 avg=2.55\n",
            "[288 | 671.18] loss=2.44 avg=2.55\n",
            "[289 | 673.41] loss=2.54 avg=2.55\n",
            "[290 | 675.65] loss=2.51 avg=2.55\n",
            "[291 | 677.88] loss=2.06 avg=2.54\n",
            "[292 | 680.12] loss=2.40 avg=2.54\n",
            "[293 | 682.35] loss=2.06 avg=2.53\n",
            "[294 | 684.59] loss=2.31 avg=2.53\n",
            "[295 | 686.83] loss=2.36 avg=2.53\n",
            "[296 | 689.06] loss=2.18 avg=2.53\n",
            "[297 | 691.29] loss=2.33 avg=2.52\n",
            "[298 | 693.53] loss=2.20 avg=2.52\n",
            "[299 | 695.76] loss=2.18 avg=2.52\n",
            "[300 | 697.99] loss=2.14 avg=2.51\n",
            "======== SAMPLE 1 ========\n",
            ", he thought. \n",
            "He remembered how it had been. It was the death of Lord Karstark, his father's, but it too had been a battle . . . a struggle \n",
            "over who was to keep Karstark alive. Tyrion could feel the long, white hair of Jaime Lannister down his \n",
            "thighs, but no sooner had Ser Gregor's smile come to him. It had come from the way Gregor and his \n",
            "brother Jon used to talk. Tyrion knew who he was; twenty-one years older than them, and \n",
            "still a squire strong on his shoulders, yet the younger son of the Lord Commander of the Kingsguard, and \n",
            "the first person Tyrion had ever known to call himself \"the Lord of the Rings.\" His father called him \"the \n",
            "Lord of the Rings.\" \n",
            "He had not known the last name . . . and not even the last word, yet here in his own skin, it had been so much bigger than it had \n",
            "been. Lord Karstark was the godfather of dragons, born that winter in the fire of Cather, at \n",
            "the edge of the forest where dragons had once lived. His khalasar had killed all those dragons to create that \n",
            "flames of flame and green, and had taken half an island with them, the dragonflies that still lay in the \n",
            "forest to keep them alive and fragrant. The flame was the dragon's egg, Tyrion remembered, and \n",
            "once a dragon had caught a man's leg and split it open and tear off his flesh, killing him instantly. \n",
            "And there in the moonlight, the sound of their voices mingled, and Lord Karstark's name was heard not by \n",
            "every man in the east. It came thundering down across the realm, from the east and northwest. \n",
            "\"You say they fought between forty thousand warriors?\" Ser Gregor Cassel, the lord of the Eyrie, asked \n",
            "his son-in-arms in a soft voice. \n",
            "\"No,\" Tyrion acknowledged. \"I mean they had forty thousand strong.\" \n",
            "\"Damn them,\" Gregor answered in those quiet and sad tones. \"We can sweep them from the Eyrie too if you like, \n",
            "or make it go off forever.\" \n",
            "It was a long night. \n",
            "His father drove his car through a small hamlet where the peasants gathered the land. He said he would \n",
            "make plans soon. It was a long way from his father's city, surrounded on all sides by small hills to the \n",
            "bottom of the hills, where the hills are flat and dead and never changing. \n",
            "They would ride east from there to the mountain hamlets of the west, through deep forests where the air \n",
            "seemed strange and oppressive and the water so fresh that the leaves were sticky green over \n",
            "brown and brittle. Tyrion was certain that he and his father still called each other the \"Grangers\" by \n",
            "now. \n",
            "His father was always kind and courteous, but sometimes it made him angry, when he came to see him at the wedding \n",
            "of Lannister and Pycelle, and the knights had sent him packing when he was away. He had been so \n",
            "mean and rough, though, that even his sister, Tanda, forgave him nonetheless. Perhaps because of that, \n",
            "his father liked well. That was the best father's gift; the quickness with which you can cut a man \n",
            "off's head and toss it to him. You also learn to put aside your anger in favor of your good sense, it \n",
            "fails. Tyrion knew how to put aside his angry feelings and just fight with them. A fortnight ago they had \n",
            "woken him and said he had come safely to Dorne, but he had not slept in a long time, and his dream had \n",
            "lain in his head for hours. He was waking from a long day's sleep by the time they had to be \n",
            "re-entering the kitchens where they'd brought him food. So he had slept, and had not slept. \n",
            "He had not slept yet, at least, not without the knights telling him. They were waiting outside to \n",
            "ask him about his visions. When the king arrived, he had his armor ripped from its hilt and \n",
            "bald from its cowl, with a great gorget over it, a pair of bright white arrows set in a great iron ring. Tyrion \n",
            "had found some gold on display; a dozen heads to his father's left; a long row of arrows in his belt, engraved with \n",
            "black runes and painted black, and in their hands a golden bow of dark green metal. \n",
            "\"Are you a man?\" Grand Maester Luwin asked. He and Pycelle shared a frown. \n",
            "Page 197\n",
            "\n",
            "[301 | 711.62] loss=2.67 avg=2.52\n",
            "[302 | 713.85] loss=2.36 avg=2.51\n",
            "[303 | 716.09] loss=2.32 avg=2.51\n",
            "[304 | 718.32] loss=2.39 avg=2.51\n",
            "[305 | 720.55] loss=2.38 avg=2.51\n",
            "[306 | 722.78] loss=2.23 avg=2.51\n",
            "[307 | 725.01] loss=2.43 avg=2.51\n",
            "[308 | 727.25] loss=2.19 avg=2.50\n",
            "[309 | 729.48] loss=2.36 avg=2.50\n",
            "[310 | 731.71] loss=2.27 avg=2.50\n",
            "[311 | 733.94] loss=2.38 avg=2.50\n",
            "[312 | 736.17] loss=2.43 avg=2.50\n",
            "[313 | 738.41] loss=2.34 avg=2.49\n",
            "[314 | 740.66] loss=2.33 avg=2.49\n",
            "[315 | 742.89] loss=2.20 avg=2.49\n",
            "[316 | 745.13] loss=2.15 avg=2.49\n",
            "[317 | 747.37] loss=2.32 avg=2.48\n",
            "[318 | 749.60] loss=2.56 avg=2.49\n",
            "[319 | 751.83] loss=2.31 avg=2.48\n",
            "[320 | 754.07] loss=2.12 avg=2.48\n",
            "[321 | 756.30] loss=2.24 avg=2.48\n",
            "[322 | 758.53] loss=2.06 avg=2.47\n",
            "[323 | 760.77] loss=2.06 avg=2.47\n",
            "[324 | 763.00] loss=2.31 avg=2.47\n",
            "[325 | 765.25] loss=2.20 avg=2.46\n",
            "[326 | 767.48] loss=2.71 avg=2.47\n",
            "[327 | 769.72] loss=2.49 avg=2.47\n",
            "[328 | 771.95] loss=2.05 avg=2.46\n",
            "[329 | 774.18] loss=2.20 avg=2.46\n",
            "[330 | 776.42] loss=2.30 avg=2.46\n",
            "[331 | 778.66] loss=2.22 avg=2.46\n",
            "[332 | 780.89] loss=2.15 avg=2.45\n",
            "[333 | 783.13] loss=2.20 avg=2.45\n",
            "[334 | 785.36] loss=2.04 avg=2.45\n",
            "[335 | 787.59] loss=2.57 avg=2.45\n",
            "[336 | 789.85] loss=2.11 avg=2.44\n",
            "[337 | 792.08] loss=2.20 avg=2.44\n",
            "[338 | 794.31] loss=2.37 avg=2.44\n",
            "[339 | 796.55] loss=2.13 avg=2.44\n",
            "[340 | 798.78] loss=2.20 avg=2.43\n",
            "[341 | 801.02] loss=2.42 avg=2.43\n",
            "[342 | 803.25] loss=2.11 avg=2.43\n",
            "[343 | 805.49] loss=2.27 avg=2.43\n",
            "[344 | 807.72] loss=2.52 avg=2.43\n",
            "[345 | 809.96] loss=2.17 avg=2.43\n",
            "[346 | 812.19] loss=2.24 avg=2.43\n",
            "[347 | 814.44] loss=2.26 avg=2.42\n",
            "[348 | 816.67] loss=2.01 avg=2.42\n",
            "[349 | 818.90] loss=2.31 avg=2.42\n",
            "[350 | 821.14] loss=2.11 avg=2.42\n",
            "[351 | 823.37] loss=2.11 avg=2.41\n",
            "[352 | 825.62] loss=2.24 avg=2.41\n",
            "[353 | 827.85] loss=2.46 avg=2.41\n",
            "[354 | 830.09] loss=2.32 avg=2.41\n",
            "[355 | 832.32] loss=1.96 avg=2.41\n",
            "[356 | 834.56] loss=2.15 avg=2.40\n",
            "[357 | 836.79] loss=2.39 avg=2.40\n",
            "[358 | 839.03] loss=1.83 avg=2.40\n",
            "[359 | 841.25] loss=2.27 avg=2.40\n",
            "[360 | 843.49] loss=2.11 avg=2.39\n",
            "[361 | 845.72] loss=1.85 avg=2.39\n",
            "[362 | 847.95] loss=2.18 avg=2.38\n",
            "[363 | 850.19] loss=2.16 avg=2.38\n",
            "[364 | 852.43] loss=2.07 avg=2.38\n",
            "[365 | 854.66] loss=1.96 avg=2.38\n",
            "[366 | 856.89] loss=2.08 avg=2.37\n",
            "[367 | 859.12] loss=2.26 avg=2.37\n",
            "[368 | 861.36] loss=2.09 avg=2.37\n",
            "[369 | 863.60] loss=2.17 avg=2.37\n",
            "[370 | 865.83] loss=2.02 avg=2.36\n",
            "[371 | 868.06] loss=1.81 avg=2.36\n",
            "[372 | 870.29] loss=2.25 avg=2.36\n",
            "[373 | 872.53] loss=2.17 avg=2.35\n",
            "[374 | 874.76] loss=2.24 avg=2.35\n",
            "[375 | 876.99] loss=1.87 avg=2.35\n",
            "[376 | 879.23] loss=2.41 avg=2.35\n",
            "[377 | 881.46] loss=2.11 avg=2.35\n",
            "[378 | 883.69] loss=2.17 avg=2.34\n",
            "[379 | 885.92] loss=2.00 avg=2.34\n",
            "[380 | 888.17] loss=2.02 avg=2.34\n",
            "[381 | 890.39] loss=2.06 avg=2.33\n",
            "[382 | 892.63] loss=2.36 avg=2.33\n",
            "[383 | 894.85] loss=1.89 avg=2.33\n",
            "[384 | 897.09] loss=1.96 avg=2.33\n",
            "[385 | 899.32] loss=2.43 avg=2.33\n",
            "[386 | 901.55] loss=2.26 avg=2.33\n",
            "[387 | 903.78] loss=2.15 avg=2.32\n",
            "[388 | 906.01] loss=2.04 avg=2.32\n",
            "[389 | 908.25] loss=1.92 avg=2.32\n",
            "[390 | 910.48] loss=1.82 avg=2.31\n",
            "[391 | 912.71] loss=1.95 avg=2.31\n",
            "[392 | 914.95] loss=1.73 avg=2.30\n",
            "[393 | 917.18] loss=2.45 avg=2.30\n",
            "[394 | 919.42] loss=1.95 avg=2.30\n",
            "[395 | 921.65] loss=1.95 avg=2.30\n",
            "[396 | 923.89] loss=2.10 avg=2.30\n",
            "[397 | 926.13] loss=1.97 avg=2.29\n",
            "[398 | 928.36] loss=2.07 avg=2.29\n",
            "[399 | 930.59] loss=2.02 avg=2.29\n",
            "[400 | 932.82] loss=2.32 avg=2.29\n",
            "======== SAMPLE 1 ========\n",
            " thinking.\" \n",
            "Alyn looked from him to where he was holding the dagger at his belt. \"As you asked, but I . . . do not \n",
            "want to live like that.\" \n",
            "\"This won't be your death . . . this is only a dagger,\" the knight said, a grim smile on his lips. \n",
            "\"I will make you pay. You are the bravo with the golden cloaks.\" \n",
            "Page 578\n",
            "\n",
            "AN: \n",
            "I am not the best swordsmith in the Vale. \n",
            "Ned had made a great deal of money riding wooden swords, but he could not cut with a \n",
            "blade after that, so he always went with a wooden sword. The sword he carried was a heavy \n",
            "double-curved steel forged in the shape of a dragon, with a dragon's horn in the center, but \n",
            "Ned had always favored finer weapons with a dragon's horn in its center, as he knew well. \n",
            "He carried a pair of longswords: one in hand and a spear of every sort. \n",
            "He had made a great profit riding a double-curved steel sword, so much so that he felt \n",
            "good about himself; the armor was more than most. Ned had a rare fascination for the dragon, he \n",
            "gave it to him daily, and for half the week he was out riding, he had never seen it. That \n",
            "would not be his first rode with the beast, but when Lord Renly brought the beast back from \n",
            "the Trident and showed Ned the steel with the gold of his pride, there was nothing it \n",
            "could not hide. \n",
            "He wore the longsword almost as often as he carried his armor. \"You must wear it as you must wear \n",
            "armor,\" Ser Barristan said. \"I can make you this. If I had to pick one, I would choose armor I \n",
            "might as well wear. For you, Ser Barristan.\" \n",
            "\"In truth, of course I would,\" Ned said, \"but armor is only a helm, not a helm- it will do when \n",
            "you shift back to your steel. This is armor I am paid to wear. I will have you join me to my \n",
            "armor.\" \n",
            "That was when Ser Barristan had first appeared. He was short, stocky, dressed like a dwarf. His \n",
            "armor was long and chiseled, with a bronze shield and bronze medallion shield on the breast. He had a \n",
            "silver ring under one eye, and a silvery metal belt around his neck. He did not appear to have a \n",
            "mouth or a mouth for swallowing. \n",
            "\"Gravitational,\" Ser Barristan said softly. \"The godswife has told me of this dwarf.\" The \n",
            "wisps of gold in his brown eyes widened in surprise. \"I don't know who this dwarf is, I . . . I . . \n",
            "Truly, he has no business traveling the world. I mean, he will make one of a kind. He will \n",
            "ride the earth. That he has thought that trip as well. Perhaps his eyes are still made for \n",
            "drifting.\" \n",
            "Ned studied the dwarf. \"The gods only know what he will be like, but it seems he will be \n",
            "unafraid to admit that he's been lost in the night like many other men.\" \n",
            "\"In the mountains?\" the dwarf asked quietly. \"Mists see far too many drow.\" \n",
            "\"I will tell him,\" Ned said. \"He will be fine. Be safe.\" \n",
            "Ned moved closer to the dwarf. He would have loved to climb, for all his lost wisdom, but what Ned \n",
            "did not know is that a dwarf could climb just about anywhere. No matter where you were \n",
            "at the end of the world, people would chase you. \"Might I ask you about your brother . . .\" \n",
            "Ned nodded and followed the dwarf up to his chin. \"He was with the Night's Watch after all.\" \n",
            "\"Uncle Benjen kept the wolf, and Grand Maester Thorne when the king was too sick to stand \n",
            "by. Grand Maester Bryceane was an old friend, but I trust he didn't ask much of you at all.\" \n",
            "Dwarf on horseback, pale as milk, the direwolf huddling beside his huge white fur \n",
            "head. Ned slid the dagger that was left under the bed to his left. Even with the dagger in \n",
            "hand, it was scarcely a bear's strength. \n",
            "\"We'll see how cold it gets,\" Lord Petyr suggested. \"In the north, the sun is a little \n",
            "hot. In the south, the sky blazes.\" \n",
            "\"They are very hot,\" said Pycelle, \"but the cold is cold\n",
            "\n",
            "[401 | 946.24] loss=1.81 avg=2.28\n",
            "[402 | 948.48] loss=2.02 avg=2.28\n",
            "[403 | 950.71] loss=2.05 avg=2.28\n",
            "[404 | 952.94] loss=2.15 avg=2.28\n",
            "[405 | 955.17] loss=1.71 avg=2.27\n",
            "[406 | 957.40] loss=2.05 avg=2.27\n",
            "[407 | 959.64] loss=2.37 avg=2.27\n",
            "[408 | 961.88] loss=2.17 avg=2.27\n",
            "[409 | 964.12] loss=1.94 avg=2.26\n",
            "[410 | 966.35] loss=1.95 avg=2.26\n",
            "[411 | 968.59] loss=1.88 avg=2.26\n",
            "[412 | 970.82] loss=1.81 avg=2.25\n",
            "[413 | 973.06] loss=1.86 avg=2.25\n",
            "[414 | 975.29] loss=1.74 avg=2.24\n",
            "[415 | 977.53] loss=2.23 avg=2.24\n",
            "[416 | 979.77] loss=2.13 avg=2.24\n",
            "[417 | 982.00] loss=1.95 avg=2.24\n",
            "[418 | 984.24] loss=2.04 avg=2.24\n",
            "[419 | 986.48] loss=1.89 avg=2.23\n",
            "[420 | 988.72] loss=2.23 avg=2.23\n",
            "[421 | 990.96] loss=1.99 avg=2.23\n",
            "[422 | 993.20] loss=2.12 avg=2.23\n",
            "[423 | 995.44] loss=1.81 avg=2.23\n",
            "[424 | 997.67] loss=1.65 avg=2.22\n",
            "[425 | 999.91] loss=1.85 avg=2.22\n",
            "[426 | 1002.14] loss=2.12 avg=2.22\n",
            "[427 | 1004.38] loss=1.91 avg=2.21\n",
            "[428 | 1006.62] loss=2.26 avg=2.21\n",
            "[429 | 1008.86] loss=1.88 avg=2.21\n",
            "[430 | 1011.09] loss=2.10 avg=2.21\n",
            "[431 | 1013.33] loss=1.76 avg=2.20\n",
            "[432 | 1015.56] loss=1.85 avg=2.20\n",
            "[433 | 1017.80] loss=2.01 avg=2.20\n",
            "[434 | 1020.03] loss=2.12 avg=2.20\n",
            "[435 | 1022.27] loss=1.92 avg=2.19\n",
            "[436 | 1024.51] loss=2.11 avg=2.19\n",
            "[437 | 1026.76] loss=1.87 avg=2.19\n",
            "[438 | 1028.99] loss=1.87 avg=2.19\n",
            "[439 | 1031.22] loss=1.98 avg=2.19\n",
            "[440 | 1033.46] loss=2.17 avg=2.19\n",
            "[441 | 1035.69] loss=1.60 avg=2.18\n",
            "[442 | 1037.94] loss=1.80 avg=2.18\n",
            "[443 | 1040.17] loss=1.82 avg=2.17\n",
            "[444 | 1042.40] loss=2.17 avg=2.17\n",
            "[445 | 1044.64] loss=1.95 avg=2.17\n",
            "[446 | 1046.88] loss=1.97 avg=2.17\n",
            "[447 | 1049.12] loss=1.67 avg=2.16\n",
            "[448 | 1051.35] loss=1.89 avg=2.16\n",
            "[449 | 1053.59] loss=1.80 avg=2.16\n",
            "[450 | 1055.82] loss=2.02 avg=2.15\n",
            "[451 | 1058.06] loss=2.03 avg=2.15\n",
            "[452 | 1060.30] loss=2.12 avg=2.15\n",
            "[453 | 1062.53] loss=1.81 avg=2.15\n",
            "[454 | 1064.76] loss=1.71 avg=2.15\n",
            "[455 | 1067.00] loss=1.74 avg=2.14\n",
            "[456 | 1069.22] loss=1.77 avg=2.14\n",
            "[457 | 1071.46] loss=1.54 avg=2.13\n",
            "[458 | 1073.70] loss=1.69 avg=2.13\n",
            "[459 | 1075.93] loss=2.27 avg=2.13\n",
            "[460 | 1078.16] loss=1.95 avg=2.13\n",
            "[461 | 1080.39] loss=1.62 avg=2.12\n",
            "[462 | 1082.62] loss=1.69 avg=2.12\n",
            "[463 | 1084.86] loss=1.79 avg=2.11\n",
            "[464 | 1087.08] loss=1.57 avg=2.11\n",
            "[465 | 1089.31] loss=1.82 avg=2.11\n",
            "[466 | 1091.55] loss=1.55 avg=2.10\n",
            "[467 | 1093.79] loss=1.54 avg=2.09\n",
            "[468 | 1096.03] loss=1.47 avg=2.09\n",
            "[469 | 1098.27] loss=1.68 avg=2.08\n",
            "[470 | 1100.50] loss=1.42 avg=2.08\n",
            "[471 | 1102.73] loss=1.94 avg=2.08\n",
            "[472 | 1104.96] loss=1.87 avg=2.07\n",
            "[473 | 1107.20] loss=2.07 avg=2.07\n",
            "[474 | 1109.44] loss=1.92 avg=2.07\n",
            "[475 | 1111.67] loss=1.90 avg=2.07\n",
            "[476 | 1113.89] loss=2.19 avg=2.07\n",
            "[477 | 1116.12] loss=1.67 avg=2.07\n",
            "[478 | 1118.35] loss=1.73 avg=2.06\n",
            "[479 | 1120.59] loss=1.70 avg=2.06\n",
            "[480 | 1122.82] loss=1.95 avg=2.06\n",
            "[481 | 1125.05] loss=1.53 avg=2.05\n",
            "[482 | 1127.28] loss=1.72 avg=2.05\n",
            "[483 | 1129.51] loss=1.69 avg=2.05\n",
            "[484 | 1131.75] loss=1.62 avg=2.04\n",
            "[485 | 1133.98] loss=1.58 avg=2.04\n",
            "[486 | 1136.21] loss=1.61 avg=2.03\n",
            "[487 | 1138.44] loss=1.60 avg=2.03\n",
            "[488 | 1140.68] loss=1.84 avg=2.03\n",
            "[489 | 1142.91] loss=1.85 avg=2.03\n",
            "[490 | 1145.15] loss=1.63 avg=2.02\n",
            "[491 | 1147.38] loss=1.88 avg=2.02\n",
            "[492 | 1149.61] loss=1.96 avg=2.02\n",
            "[493 | 1151.84] loss=1.72 avg=2.02\n",
            "[494 | 1154.07] loss=2.00 avg=2.02\n",
            "[495 | 1156.31] loss=1.62 avg=2.01\n",
            "[496 | 1158.54] loss=1.35 avg=2.01\n",
            "[497 | 1160.77] loss=1.77 avg=2.00\n",
            "[498 | 1163.00] loss=1.80 avg=2.00\n",
            "[499 | 1165.23] loss=1.49 avg=2.00\n",
            "[500 | 1167.46] loss=1.60 avg=1.99\n",
            "Saving checkpoint/run1/model-500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Text generation"
      ],
      "metadata": {
        "id": "bUagiJzBTeoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prefix = \"Is there a life after death?\""
      ],
      "metadata": {
        "id": "qzTK7bdIPeOY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.generate(sess, prefix=prefix, length=150)"
      ],
      "metadata": {
        "id": "ZCaaNXR7kI9I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "333e0601-a82a-4549-e2c5-eeacfc9f18b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is there a life after death? What can you say? \n",
            "Page 471\n",
            "\n",
            "You said it would be so. You are the Lord of the Seven Kingdoms, after all. \n",
            "Alyn Tully was alone. She had the strength of a bear. She had the strength to bare the dark against the \n",
            "dark lords of the north. She could take them all. \n",
            "Catelyn gazed at her husband. The wolf of Asshai, the direwolf of the snows. She would marry \n",
            "him, and have a son together. Let them both live the rest of their days with the same soft, innocent \n",
            "beauty. Let them laugh together, and call each other brother and sister. Let them run together for ever and ever\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Saving model to Google Drive (optional)"
      ],
      "metadata": {
        "id": "zlM6aQYZSccl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "QYXmOFl5Bjhv",
        "outputId": "1a490e92-79c9-4424-9b7b-a7dda30f44cb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "metadata": {
        "id": "3RUjr4_ZluKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can find more texts e.g. on:\n",
        "https://www.gutenberg.org/cache/epub/1597/pg1597.txt\n",
        "</br></br>\n",
        "You can download them to Colab using code similar to the ones below."
      ],
      "metadata": {
        "id": "OUhaGg_uS6o5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://www.gutenberg.org/cache/epub/1597/pg1597.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7K9X3K8TEwj",
        "outputId": "d0760c42-a0e4-4dcf-b7cc-ca98aaffa2b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-21 14:49:16--  https://www.gutenberg.org/cache/epub/1597/pg1597.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 329071 (321K) [text/plain]\n",
            "Saving to: â€˜pg1597.txtâ€™\n",
            "\n",
            "pg1597.txt          100%[===================>] 321.36K   800KB/s    in 0.4s    \n",
            "\n",
            "2023-03-21 14:49:22 (800 KB/s) - â€˜pg1597.txtâ€™ saved [329071/329071]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://www.gutenberg.org/files/98/98-0.txt"
      ],
      "metadata": {
        "id": "HYL0wij2m4Gf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42bf360b-ce90-4a36-d434-44820124b877"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-22 13:25:10--  https://www.gutenberg.org/files/98/98-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 807231 (788K) [text/plain]\n",
            "Saving to: â€˜98-0.txtâ€™\n",
            "\n",
            "98-0.txt            100%[===================>] 788.31K   718KB/s    in 1.1s    \n",
            "\n",
            "2023-02-22 13:25:12 (718 KB/s) - â€˜98-0.txtâ€™ saved [807231/807231]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/matt-dray/tng-stardate/tree/master/data/scripts"
      ],
      "metadata": {
        "id": "VClsbkgRxYvR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}